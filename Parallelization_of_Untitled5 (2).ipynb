{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8vWMcsQlFOX",
    "outputId": "59d1f854-0924-4bb0-c518-3c85b48be8fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./tf/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: gpytorch in ./tf/lib/python3.7/site-packages (1.8.1)\n",
      "Requirement already satisfied: typing-extensions in ./tf/lib/python3.7/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./tf/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./tf/lib/python3.7/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./tf/lib/python3.7/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./tf/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in ./tf/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (40.6.2)\n",
      "Requirement already satisfied: wheel in ./tf/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.42.0)\n",
      "Requirement already satisfied: numpy in ./tf/lib/python3.7/site-packages (from gpytorch) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn in ./tf/lib/python3.7/site-packages (from gpytorch) (1.0.2)\n",
      "Requirement already satisfied: scipy in ./tf/lib/python3.7/site-packages (from gpytorch) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in ./tf/lib/python3.7/site-packages (from scikit-learn->gpytorch) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./tf/lib/python3.7/site-packages (from scikit-learn->gpytorch) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y727isCWmUiP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Temp\\ipykernel_9308\\411477941.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\__init__.py\", line 1471, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('df_scaled.csv')\n",
    "\n",
    "df = df.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9aJxNnrl_lt",
    "outputId": "391b9ddc-d11c-4942-8a49-f9abfbdfcde0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84466"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test= round(0.2*  df.shape[0])\n",
    "n_test\n",
    "n_train= df.shape[0]-n_test\n",
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3FTevPigjJ0X",
    "outputId": "ea039a3e-c0f6-4ec4-f477-5697b01c246d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 105582 entries, 0 to 164147\n",
      "Data columns (total 70 columns):\n",
      " #   Column                                                         Non-Null Count   Dtype  \n",
      "---  ------                                                         --------------   -----  \n",
      " 0   surfaceProcessingLocationCavity                                105582 non-null  float64\n",
      " 1   hotRunner                                                      105582 non-null  float64\n",
      " 2   hotRunnerCost                                                  105582 non-null  float64\n",
      " 3   manufacturingCost                                              105582 non-null  float64\n",
      " 4   mouldValidationCost                                            105582 non-null  float64\n",
      " 5   designTime                                                     105582 non-null  float64\n",
      " 6   hourlyDesignCost                                               105582 non-null  float64\n",
      " 7   removedChassis                                                 105582 non-null  float64\n",
      " 8   weightChassisProcessed                                         105582 non-null  float64\n",
      " 9   surfaceProcessingLocationChassis                               105582 non-null  float64\n",
      " 10  removedCavity                                                  105582 non-null  float64\n",
      " 11  numberOfCavities                                               105582 non-null  float64\n",
      " 12  weightCavityProcessed                                          105582 non-null  float64\n",
      " 13  weightMould                                                    105582 non-null  float64\n",
      " 14  totalTransportationPercentage                                  105582 non-null  float64\n",
      " 15  percentageAircraft                                             105582 non-null  float64\n",
      " 16  percentageLorry                                                105582 non-null  float64\n",
      " 17  percentageTrain                                                105582 non-null  float64\n",
      " 18  percentageShip                                                 105582 non-null  float64\n",
      " 19  totalDistance                                                  105582 non-null  float64\n",
      " 20  transportCost                                                  105582 non-null  float64\n",
      " 21  injectedMaterial_product                                       105582 non-null  float64\n",
      " 22  injectedMaterialCost                                           105582 non-null  float64\n",
      " 23  percentageRecycledMaterial                                     105582 non-null  float64\n",
      " 24  maxDepth                                                       105582 non-null  float64\n",
      " 25  maxWallThickness                                               105582 non-null  float64\n",
      " 26  productVolume                                                  105582 non-null  float64\n",
      " 27  materozzaVolume                                                105582 non-null  float64\n",
      " 28  nAnniProduzione                                                105582 non-null  float64\n",
      " 29  nProdottiAnno                                                  105582 non-null  float64\n",
      " 30  materialDensity                                                105582 non-null  float64\n",
      " 31  tolerance                                                      105582 non-null  float64\n",
      " 32  surfaceFinishing                                               105582 non-null  float64\n",
      " 33  cycleTime                                                      105582 non-null  float64\n",
      " 34  machineCycleTime                                               105582 non-null  float64\n",
      " 35  maintenanceCost                                                105582 non-null  float64\n",
      " 36  productionCost                                                 105582 non-null  float64\n",
      " 37  injectedMaterial_materozza                                     105582 non-null  float64\n",
      " 38  injectionMouldingProcess                                       105582 non-null  float64\n",
      " 39  memtiEngineValue                                               105582 non-null  float64\n",
      " 40  steelPrice                                                     105582 non-null  float64\n",
      " 41  runnersType                                                    105582 non-null  float64\n",
      " 42  mouldMaterialName                                              105582 non-null  float64\n",
      " 43  machineName                                                    105582 non-null  float64\n",
      " 44  EUUSMacchina                                                   105582 non-null  float64\n",
      " 45  CNMacchina                                                     105582 non-null  float64\n",
      " 46  gateDiameter                                                   105582 non-null  float64\n",
      " 47  setupTime                                                      105582 non-null  float64\n",
      " 48  warmupTime                                                     105582 non-null  float64\n",
      " 49  deliveryVolume                                                 105582 non-null  float64\n",
      " 50  deliveryPeriod                                                 105582 non-null  float64\n",
      " 51  mouldDesignCostDisplay                                         105582 non-null  float64\n",
      " 52  mouldTotalCost                                                 105582 non-null  float64\n",
      " 53  Cost                                                           105582 non-null  float64\n",
      " 54  human health - photochemical oxidation                         105582 non-null  float64\n",
      " 55  ecosystem quality - terrestrial ecotoxicity                    105582 non-null  float64\n",
      " 56  resources - mineral extraction                                 105582 non-null  float64\n",
      " 57  resources - non-renewable energy                               105582 non-null  float64\n",
      " 58  ecosystem quality - terrestrial acidification & nutrification  105582 non-null  float64\n",
      " 59  resources - total                                              105582 non-null  float64\n",
      " 60  human health - ionising radiation                              105582 non-null  float64\n",
      " 61  human health - respiratory effects (inorganics)                105582 non-null  float64\n",
      " 62  human health - total                                           105582 non-null  float64\n",
      " 63  human health - human toxicity                                  105582 non-null  float64\n",
      " 64  ecosystem quality - aquatic ecotoxicity                        105582 non-null  float64\n",
      " 65  climate change - climate change                                105582 non-null  float64\n",
      " 66  human health - ozone layer depletion                           105582 non-null  float64\n",
      " 67  ecosystem quality - land occupation                            105582 non-null  float64\n",
      " 68  climate change - total                                         105582 non-null  float64\n",
      " 69  ecosystem quality - total                                      105582 non-null  float64\n",
      "dtypes: float64(70)\n",
      "memory usage: 57.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "iJbYC1Vfmdl0",
    "outputId": "ac27100b-2f8a-4943-dc9b-41f2702cf257"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surfaceProcessingLocationCavity</th>\n",
       "      <th>hotRunner</th>\n",
       "      <th>hotRunnerCost</th>\n",
       "      <th>manufacturingCost</th>\n",
       "      <th>mouldValidationCost</th>\n",
       "      <th>designTime</th>\n",
       "      <th>hourlyDesignCost</th>\n",
       "      <th>removedChassis</th>\n",
       "      <th>weightChassisProcessed</th>\n",
       "      <th>surfaceProcessingLocationChassis</th>\n",
       "      <th>...</th>\n",
       "      <th>human health - ionising radiation</th>\n",
       "      <th>human health - respiratory effects (inorganics)</th>\n",
       "      <th>human health - total</th>\n",
       "      <th>human health - human toxicity</th>\n",
       "      <th>ecosystem quality - aquatic ecotoxicity</th>\n",
       "      <th>climate change - climate change</th>\n",
       "      <th>human health - ozone layer depletion</th>\n",
       "      <th>ecosystem quality - land occupation</th>\n",
       "      <th>climate change - total</th>\n",
       "      <th>ecosystem quality - total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.003202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.003192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.001926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.001915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   surfaceProcessingLocationCavity  hotRunner  hotRunnerCost  \\\n",
       "0                              0.5        1.0            1.0   \n",
       "1                              0.5        1.0            1.0   \n",
       "2                              0.5        0.0            1.0   \n",
       "3                              0.5        1.0            0.0   \n",
       "4                              0.5        0.0            0.5   \n",
       "\n",
       "   manufacturingCost  mouldValidationCost  designTime  hourlyDesignCost  \\\n",
       "0                0.5                  0.0         0.0               1.0   \n",
       "1                0.0                  0.5         0.5               0.0   \n",
       "2                0.5                  1.0         1.0               1.0   \n",
       "3                0.0                  1.0         0.5               0.0   \n",
       "4                0.0                  0.5         0.0               1.0   \n",
       "\n",
       "   removedChassis  weightChassisProcessed  surfaceProcessingLocationChassis  \\\n",
       "0        0.666667                     0.0                               0.0   \n",
       "1        0.000000                     0.0                               0.0   \n",
       "2        0.666667                     0.0                               0.0   \n",
       "3        0.400000                     0.0                               0.0   \n",
       "4        0.400000                     0.0                               0.0   \n",
       "\n",
       "   ...  human health - ionising radiation  \\\n",
       "0  ...                           0.000524   \n",
       "1  ...                           0.000075   \n",
       "2  ...                           0.000522   \n",
       "3  ...                           0.000315   \n",
       "4  ...                           0.000313   \n",
       "\n",
       "   human health - respiratory effects (inorganics)  human health - total  \\\n",
       "0                                         0.001147              0.001123   \n",
       "1                                         0.000045              0.000054   \n",
       "2                                         0.001143              0.001119   \n",
       "3                                         0.000690              0.000675   \n",
       "4                                         0.000686              0.000671   \n",
       "\n",
       "   human health - human toxicity  ecosystem quality - aquatic ecotoxicity  \\\n",
       "0                       0.003098                                 0.001833   \n",
       "1                       0.000039                                 0.000029   \n",
       "2                       0.003088                                 0.001827   \n",
       "3                       0.001863                                 0.001102   \n",
       "4                       0.001853                                 0.001096   \n",
       "\n",
       "   climate change - climate change  human health - ozone layer depletion  \\\n",
       "0                         0.000650                              0.000886   \n",
       "1                         0.000032                              0.000043   \n",
       "2                         0.000647                              0.000883   \n",
       "3                         0.000391                              0.000533   \n",
       "4                         0.000388                              0.000530   \n",
       "\n",
       "   ecosystem quality - land occupation  climate change - total  \\\n",
       "0                             0.002312                0.000650   \n",
       "1                             0.000055                0.000032   \n",
       "2                             0.002304                0.000647   \n",
       "3                             0.001390                0.000391   \n",
       "4                             0.001382                0.000388   \n",
       "\n",
       "   ecosystem quality - total  \n",
       "0                   0.003202  \n",
       "1                   0.000038  \n",
       "2                   0.003192  \n",
       "3                   0.001926  \n",
       "4                   0.001915  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PKmSnr5thjmX"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0-Exst-Bz8e-"
   },
   "outputs": [],
   "source": [
    "#label_col= target= output_variables\n",
    "label_col=        ['human health - total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ynCRUd3y0rvG"
   },
   "outputs": [],
   "source": [
    "input_variables= ['surfaceProcessingLocationCavity', 'hotRunner',\n",
    "'hotRunnerCost','manufacturingCost', 'mouldValidationCost',\n",
    "'designTime','hourlyDesignCost', 'removedChassis', 'weightChassisProcessed',\n",
    "'surfaceProcessingLocationChassis', 'removedCavity', 'numberOfCavities',\n",
    "'weightCavityProcessed', 'weightMould',\n",
    "'totalTransportationPercentage','percentageAircraft', 'percentageLorry', 'percentageTrain','percentageShip', 'totalDistance',\n",
    "'injectedMaterial_product', 'injectedMaterialCost','percentageRecycledMaterial', 'maxDepth', 'maxWallThickness','productVolume', 'materozzaVolume', 'nAnniProduzione', 'nProdottiAnno',\n",
    " 'materialDensity', 'tolerance', 'surfaceFinishing', 'cycleTime',\n",
    "'machineCycleTime',\n",
    "'maintenanceCost', 'productionCost','transportCost', 'mouldTotalCost',\n",
    "'injectedMaterial_materozza', 'injectionMouldingProcess','memtiEngineValue', 'steelPrice', 'runnersType', 'mouldMaterialName',\n",
    "'machineName', 'EUUSMacchina', 'CNMacchina', 'gateDiameter', 'setupTime', 'warmupTime', 'deliveryVolume', 'deliveryPeriod','mouldDesignCostDisplay']\n",
    "\n",
    "output_variables= ['human health - total',\n",
    "                   'ecosystem quality - total',\n",
    "                    'resources - total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TlTz8e3qookO"
   },
   "outputs": [],
   "source": [
    "#feature_cols= ['nProdottiAnno', 'steelPrice', 'deliveryVolume', 'machineCycleTime','deliveryPeriod', 'maintenanceCost', 'manufacturingCost']#resources-total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_cols= ['manufacturingCost', 'hotRunnerCost','designTime','maintenanceCost', ]#cost\n",
    "feature_cols= ['nProdottiAnno', 'steelPrice', 'deliveryVolume', 'machineCycleTime','deliveryPeriod', 'maintenanceCost', ]#human health-total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sH-vo8BpGZnk"
   },
   "outputs": [],
   "source": [
    "df = df[feature_cols + label_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "By5AtmsymaEl",
    "outputId": "381c520b-c9f4-486a-a91f-cc43bcd3598d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105582, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume last column is the target, rest are features\n",
    "X = df.iloc[:, :-1].values  # Features\n",
    "y = df.iloc[:, :1].values   # Target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iIJIt-fNm2Qm"
   },
   "outputs": [],
   "source": [
    "  # or whatever number you want for n_test\n",
    "train_x = torch.tensor(X[:n_train], dtype=torch.float32)\n",
    "train_y = torch.tensor(y[:n_train], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "w2G5LFWQnK-5"
   },
   "outputs": [],
   "source": [
    "test_x = train_x[:-n_test]  # Select first 1000 as test data\n",
    "test_y = train_y[:-n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jw4vZhNBjA-h",
    "outputId": "a437b888-2136-4f20-b97c-b84ce9e3a91d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([84466, 6])\n"
     ]
    }
   ],
   "source": [
    "# prompt: train_x size\n",
    "\n",
    "print(train_x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tj_HxsjGmlTb"
   },
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "\n",
    "class SparseGPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "            inducing_points.size(0)\n",
    "        )\n",
    "        variational_strategy = gpytorch.variational.VariationalStrategy(\n",
    "            self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "        )\n",
    "        super(SparseGPModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Define Gaussian likelihood\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# Select inducing points from the training data (choose 500 inducing points as an example)\n",
    "inducing_points = train_x[::160]  # For 80,000 samples, select every 160th point as inducing point\n",
    "\n",
    "# Instantiate the sparse GP model\n",
    "model = SparseGPModel(inducing_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A0tQ064mpMBR",
    "outputId": "09c7c142-463f-4f2c-a0eb-bf42091ce192"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inducing_points.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGgJaEKDmd13",
    "outputId": "edf870c1-2d52-4e95-85e7-70c2b5fb02c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: botorch in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.11.3)\n",
      "Requirement already satisfied: multipledispatch in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from botorch) (1.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from botorch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<=1.3,>=0.19 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from botorch) (1.3.0)\n",
      "Requirement already satisfied: torch>=1.13.1 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from botorch) (2.2.0)\n",
      "Requirement already satisfied: pyro-ppl>=1.8.4 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from botorch) (1.9.1)\n",
      "Requirement already satisfied: gpytorch==1.12 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from botorch) (1.12)\n",
      "Requirement already satisfied: linear-operator==0.5.2 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from botorch) (0.5.2)\n",
      "Requirement already satisfied: numpy<2.0 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from botorch) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gpytorch==1.12->botorch) (1.5.1)\n",
      "Requirement already satisfied: jaxtyping>=0.2.9 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from linear-operator==0.5.2->botorch) (0.2.33)\n",
      "Requirement already satisfied: typeguard~=2.13.3 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from linear-operator==0.5.2->botorch) (2.13.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyro-ppl>=1.8.4->botorch) (3.3.0)\n",
      "Requirement already satisfied: pyro-api>=0.1.1 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyro-ppl>=1.8.4->botorch) (0.1.2)\n",
      "Requirement already satisfied: tqdm>=4.36 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyro-ppl>=1.8.4->botorch) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.1->botorch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.1->botorch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.1->botorch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.1->botorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.1->botorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.13.1->botorch) (2024.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.36->pyro-ppl>=1.8.4->botorch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.13.1->botorch) (2.1.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn->gpytorch==1.12->botorch) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\saadr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn->gpytorch==1.12->botorch) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install botorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NHfgSIoyleJD"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import gpytorch\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWxwM7TlfwBR",
    "outputId": "22b872b1-243e-468b-b49d-80e06c32ca22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saadr\\AppData\\Local\\Temp\\ipykernel_21240\\3192023423.py:11: InputDataWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  model = SingleTaskGP(train_x, train_y, covar_module=gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import gpytorch\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.models import SingleTaskGP # Import SingleTaskGP\n",
    "\n",
    "# Instead of using your custom SparseGPModel, use BoTorch's SingleTaskGP\n",
    "# which already has the necessary attributes like num_outputs.\n",
    "model = SingleTaskGP(train_x, train_y, covar_module=gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()))\n",
    "\n",
    "# ... (Rest of your code remains the same) ...\n",
    "\n",
    "# Fit the model\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "# Since we are now using a SingleTaskGP, we need to use the appropriate MLL\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# ... (Rest of your code remains the same) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BmB-FaWmxRW",
    "outputId": "11865db5-91cb-49b3-dba4-c2dd4044211c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saadr\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\acquisition\\analytic.py:332: NumericsWarning: ExpectedImprovement has known numerical issues that lead to suboptimal optimization performance. It is strongly recommended to simply replace\n",
      "\n",
      "\t ExpectedImprovement \t --> \t LogExpectedImprovement \n",
      "\n",
      "instead, which fixes the issues and has the same API. See https://arxiv.org/abs/2310.20708 for details.\n",
      "  legacy_ei_numerics_warning(legacy_name=type(self).__name__)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 28538020624 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 54\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Stack lower and upper bounds to create the 2xN bounds tensor\u001b[39;00m\n\u001b[0;32m     51\u001b[0m bounds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mvstack([lower_bounds, upper_bounds]), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m---> 54\u001b[0m candidate, _ \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf\u001b[49m\u001b[43m(\u001b[49m\u001b[43macqf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Evaluate the objective function at the new candidate point\u001b[39;00m\n\u001b[0;32m     57\u001b[0m new_y \u001b[38;5;241m=\u001b[39m objective_function(candidate)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\optim\\optimize.py:543\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[1;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     gen_candidates \u001b[38;5;241m=\u001b[39m gen_candidates_scipy\n\u001b[0;32m    521\u001b[0m opt_acqf_inputs \u001b[38;5;241m=\u001b[39m OptimizeAcqfInputs(\n\u001b[0;32m    522\u001b[0m     acq_function\u001b[38;5;241m=\u001b[39macq_function,\n\u001b[0;32m    523\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     ic_gen_kwargs\u001b[38;5;241m=\u001b[39mic_gen_kwargs,\n\u001b[0;32m    542\u001b[0m )\n\u001b[1;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_acqf_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\optim\\optimize.py:564\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[1;34m(opt_inputs)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[1;32m--> 564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\optim\\optimize.py:255\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[1;34m(opt_inputs)\u001b[0m\n\u001b[0;32m    252\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m opt_inputs\u001b[38;5;241m.\u001b[39mbatch_initial_conditions\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# pyre-ignore[28]: Unexpected keyword argument `acq_function` to anonymous call.\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m \u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ic_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macq_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_restarts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43minequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minequality_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequality_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mic_gen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m batch_limit: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    270\u001b[0m     (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m     ),\n\u001b[0;32m    275\u001b[0m )\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_optimize_batch_candidates\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tensor, List[\u001b[38;5;167;01mWarning\u001b[39;00m]]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\optim\\initializers.py:418\u001b[0m, in \u001b[0;36mgen_batch_initial_conditions\u001b[1;34m(acq_function, bounds, q, num_restarts, raw_samples, fixed_features, options, inequality_constraints, equality_constraints, generator, fixed_X_fantasies)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m start_idx \u001b[38;5;241m<\u001b[39m X_rnd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    417\u001b[0m     end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start_idx \u001b[38;5;241m+\u001b[39m batch_limit, X_rnd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 418\u001b[0m     Y_rnd_curr \u001b[38;5;241m=\u001b[39m \u001b[43macq_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_rnd\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    421\u001b[0m     Y_rnd_list\u001b[38;5;241m.\u001b[39mappend(Y_rnd_curr)\n\u001b[0;32m    422\u001b[0m     start_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_limit\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\utils\\transforms.py:288\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[1;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# add t-batch dim\u001b[39;00m\n\u001b[0;32m    287\u001b[0m X \u001b[38;5;241m=\u001b[39m X \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 288\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43macqf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(acqf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_ensemble(acqf\u001b[38;5;241m.\u001b[39mmodel):\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;66;03m# IDEA: this could be wrapped into SampleReducingMCAcquisitionFunction\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    292\u001b[0m         output\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m acqf\u001b[38;5;241m.\u001b[39m_log \u001b[38;5;28;01melse\u001b[39;00m logmeanexp(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    293\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\acquisition\\analytic.py:351\u001b[0m, in \u001b[0;36mExpectedImprovement.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;129m@t_batch_mode_transform\u001b[39m(expected_q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    339\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate Expected Improvement on the candidate set X.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m        given design points `X`.\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     mean, sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean_and_sigma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m     u \u001b[38;5;241m=\u001b[39m _scaled_improvement(mean, sigma, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaximize)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sigma \u001b[38;5;241m*\u001b[39m _ei_helper(u)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\acquisition\\analytic.py:101\u001b[0m, in \u001b[0;36mAnalyticAcquisitionFunction._mean_and_sigma\u001b[1;34m(self, X, compute_sigma, min_var)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the first and second moments of the model posterior.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    returns a single tensor of means if compute_sigma is True.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# ensures buffers / parameters are on the same device\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m posterior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposterior_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_transform\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m mean \u001b[38;5;241m=\u001b[39m posterior\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# removing redundant dimensions\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compute_sigma:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\models\\gpytorch.py:446\u001b[0m, in \u001b[0;36mBatchedMultiOutputGPyTorchModel.posterior\u001b[1;34m(self, X, output_indices, observation_noise, posterior_transform)\u001b[0m\n\u001b[0;32m    440\u001b[0m     X, output_dim_idx \u001b[38;5;241m=\u001b[39m add_output_dim(\n\u001b[0;32m    441\u001b[0m         X\u001b[38;5;241m=\u001b[39mX, original_batch_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_batch_shape\n\u001b[0;32m    442\u001b[0m     )\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# NOTE: BoTorch's GPyTorchModels also inherit from GPyTorch's ExactGP, thus\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# self(X) calls GPyTorch's ExactGP's __call__, which computes the posterior,\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# rather than e.g. SingleTaskGP's forward, which computes the prior.\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m mvn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m mvn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_noise(X\u001b[38;5;241m=\u001b[39mX, mvn\u001b[38;5;241m=\u001b[39mmvn, observation_noise\u001b[38;5;241m=\u001b[39mobservation_noise)\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\models\\exact_gp.py:333\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Make the prediction\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mcg_tolerance(settings\u001b[38;5;241m.\u001b[39meval_cg_tolerance\u001b[38;5;241m.\u001b[39mvalue()):\n\u001b[0;32m    330\u001b[0m     (\n\u001b[0;32m    331\u001b[0m         predictive_mean,\n\u001b[0;32m    332\u001b[0m         predictive_covar,\n\u001b[1;32m--> 333\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;66;03m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[0;32m    336\u001b[0m predictive_mean \u001b[38;5;241m=\u001b[39m predictive_mean\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39mtest_shape)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:321\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[1;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[0;32m    317\u001b[0m     test_test_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :]\n\u001b[0;32m    318\u001b[0m     test_train_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train]\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_predictive_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_train_covar\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexact_predictive_covar(test_test_covar, test_train_covar),\n\u001b[0;32m    323\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:339\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_predictive_mean\u001b[1;34m(self, test_mean, test_train_covar)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03mComputes the posterior predictive covariance of a GP\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m:return: The predictive posterior mean of the test points\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# NOTE TO FUTURE SELF:\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;66;03m# You **cannot* use addmv here, because test_train_covar may not actually be a non lazy tensor even for an exact\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# GP, and using addmv requires you to to_dense test_train_covar, which is obviously a huge no-no!\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# see https://github.com/cornellius-gp/gpytorch/pull/2317#discussion_r1157994719\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m mean_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_cache\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mean_cache\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    341\u001b[0m     mean_cache \u001b[38;5;241m=\u001b[39m mean_cache\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:252\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.mean_cache\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_nan_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\models\\exact_prediction_strategies.py:262\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy._mean_cache\u001b[1;34m(self, nan_policy)\u001b[0m\n\u001b[0;32m    259\u001b[0m train_labels_offset \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_labels \u001b[38;5;241m-\u001b[39m train_mean)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nan_policy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 262\u001b[0m     mean_cache \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_train_covar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msolve(train_labels_offset)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nan_policy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;66;03m# Mask all rows and columns in the kernel matrix corresponding to the missing observations.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m     observed \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mobservation_nan_policy\u001b[38;5;241m.\u001b[39m_get_observed(\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_labels, torch\u001b[38;5;241m.\u001b[39mSize((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],))\n\u001b[0;32m    267\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\linear_operator\\operators\\added_diag_linear_operator.py:209\u001b[0m, in \u001b[0;36mAddedDiagLinearOperator.evaluate_kernel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_kernel\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 209\u001b[0m     added_diag_linear_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepresentation())\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m added_diag_linear_op\u001b[38;5;241m.\u001b[39m_linear_op \u001b[38;5;241m+\u001b[39m added_diag_linear_op\u001b[38;5;241m.\u001b[39m_diag_tensor\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\linear_operator\\operators\\_linear_operator.py:2064\u001b[0m, in \u001b[0;36mLinearOperator.representation_tree\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepresentation_tree\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LinearOperatorRepresentationTree:\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2056\u001b[0m \u001b[38;5;124;03m    Returns a\u001b[39;00m\n\u001b[0;32m   2057\u001b[0m \u001b[38;5;124;03m    :obj:`linear_operator.operators.LinearOperatorRepresentationTree` tree\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2062\u001b[0m \u001b[38;5;124;03m    including all subobjects. This is used internally.\u001b[39;00m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLinearOperatorRepresentationTree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\linear_operator\\operators\\linear_operator_representation_tree.py:15\u001b[0m, in \u001b[0;36mLinearOperatorRepresentationTree.__init__\u001b[1;34m(self, linear_op)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(linear_op\u001b[38;5;241m.\u001b[39m_args, linear_op\u001b[38;5;241m.\u001b[39m_differentiable_kwargs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepresentation\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(arg\u001b[38;5;241m.\u001b[39mrepresentation):  \u001b[38;5;66;03m# Is it a lazy tensor?\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m         representation_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mslice\u001b[39m(counter, counter \u001b[38;5;241m+\u001b[39m representation_size, \u001b[38;5;28;01mNone\u001b[39;00m), arg\u001b[38;5;241m.\u001b[39mrepresentation_tree()))\n\u001b[0;32m     17\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m representation_size\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:397\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.representation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrepresentation()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# Otherwise, we'll evaluate the kernel (or at least its LinearOperator representation) and use its\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# representation\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepresentation()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\utils\\memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m kwargs_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mdumps(kwargs)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_in_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _add_to_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_from_cache(\u001b[38;5;28mself\u001b[39m, cache_name, \u001b[38;5;241m*\u001b[39margs, kwargs_pkl\u001b[38;5;241m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:25\u001b[0m, in \u001b[0;36mrecall_grad_state.<locals>.wrapped\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_grad_enabled):\n\u001b[1;32m---> 25\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\lazy\\lazy_evaluated_kernel_tensor.py:355\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m     temp_active_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel\u001b[38;5;241m.\u001b[39mactive_dims \u001b[38;5;241m=\u001b[39m temp_active_dims\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\kernels\\kernel.py:530\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[1;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[0;32m    527\u001b[0m     res \u001b[38;5;241m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, last_dim_is_batch\u001b[38;5;241m=\u001b[39mlast_dim_is_batch, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     res \u001b[38;5;241m=\u001b[39m to_linear_operator(\n\u001b[1;32m--> 530\u001b[0m         \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mKernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx1_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_dim_is_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m     )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\kernels\\scale_kernel.py:118\u001b[0m, in \u001b[0;36mScaleKernel.forward\u001b[1;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     outputscales \u001b[38;5;241m=\u001b[39m outputscales\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39moutputscales\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43morig_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputscales\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 28538020624 bytes."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "'''\n",
    "# Define a sparse GP model with inducing points\n",
    "class SparseGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, inducing_points):\n",
    "        super(SparseGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel()\n",
    "        )\n",
    "        self.inducing_points = inducing_points\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x, self.inducing_points)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "inducing_points = torch.rand(10, 1)  # Sparse inducing points\n",
    "\n",
    "model = SparseGPModel(train_x, train_y, likelihood, inducing_points)\n",
    "'''\n",
    "\n",
    "# Fit the model\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "# Ensure num_data is set to the number of data points\n",
    "#mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_x.size(0))\n",
    "\n",
    "\n",
    "# Use an acquisition function (Expected Improvement in this case)\n",
    "acqf = ExpectedImprovement(model=model, best_f=train_y.max())\n",
    "\n",
    "# Find the next point to evaluate by maximizing the acquisition function\n",
    "#bounds = torch.tensor([[0.], [1.]])  # Define bounds of the search space\n",
    "# Create bounds tensor using NumPy and then convert to PyTorch tensor\n",
    "lower_bounds = np.zeros(6)\n",
    "upper_bounds = np.ones(6)  # Assuming upper bound is 1 for all features\n",
    "\n",
    "# Stack lower and upper bounds to create the 2xN bounds tensor\n",
    "bounds = torch.tensor(np.vstack([lower_bounds, upper_bounds]), dtype=torch.float)\n",
    "\n",
    "\n",
    "candidate, _ = optimize_acqf(acqf, bounds=bounds, q=1, num_restarts=2, raw_samples=5)\n",
    "\n",
    "# Evaluate the objective function at the new candidate point\n",
    "new_y = objective_function(candidate)\n",
    "\n",
    "# Update training data and repeat\n",
    "train_x = torch.cat([train_x, candidate])\n",
    "train_y = torch.cat([train_y, new_y])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Use an acquisition function (Expected Improvement in this case)\n",
    "acqf = ExpectedImprovement(model=model, best_f=train_y.max())\n",
    "\n",
    "# Find the next point to evaluate by maximizing the acquisition function\n",
    "bounds = torch.tensor([[0.], [1.]])  # Define bounds of the search space\n",
    "candidate, _ = optimize_acqf(acqf, bounds=bounds, q=1, num_restarts=5, raw_samples=20)\n",
    "\n",
    "# Evaluate the objective function at the new candidate point\n",
    "new_y = objective_function(candidate)\n",
    "\n",
    "# Update training data and repeat\n",
    "train_x = torch.cat([train_x, candidate])\n",
    "train_y = torch.cat([train_y, new_y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zeh0CVk2uco6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "3Xq18oFLlCGL",
    "outputId": "8a1851ac-6669-4a12-83de-4ddb893eef29"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SingleTaskGP' object has no attribute 'variational_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m mll \u001b[38;5;241m=\u001b[39m gpytorch\u001b[38;5;241m.\u001b[39mmlls\u001b[38;5;241m.\u001b[39mVariationalELBO(likelihood, model, num_data\u001b[38;5;241m=\u001b[39mtrain_y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m \u001b[43mfit_gpytorch_mll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Use an acquisition function (Expected Improvement in this case)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m acqf \u001b[38;5;241m=\u001b[39m ExpectedImprovement(model\u001b[38;5;241m=\u001b[39mmodel, best_f\u001b[38;5;241m=\u001b[39mtrain_y\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\fit.py:104\u001b[0m, in \u001b[0;36mfit_gpytorch_mll\u001b[1;34m(mll, closure, optimizer, closure_kwargs, optimizer_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# defer to per-method defaults\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m optimizer\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFitGPyTorchMLL\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmll\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\utils\\dispatcher.py:93\u001b[0m, in \u001b[0;36mDispatcher.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(types\u001b[38;5;241m=\u001b[39mtypes)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MDNotImplementedError:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# Traverses registered methods in order, yields whenever a match is found\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     funcs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_iter(\u001b[38;5;241m*\u001b[39mtypes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\fit.py:331\u001b[0m, in \u001b[0;36m_fit_fallback_approximate\u001b[1;34m(mll, _, __, closure, data_loader, optimizer, full_batch_limit, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    326\u001b[0m         fit_gpytorch_mll_scipy\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mll\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_targets) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m full_batch_limit\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m fit_gpytorch_mll_torch\n\u001b[0;32m    329\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fit_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\fit.py:204\u001b[0m, in \u001b[0;36m_fit_fallback\u001b[1;34m(mll, _, __, closure, optimizer, closure_kwargs, optimizer_kwargs, max_attempts, pick_best_of_all_attempts, warning_handler, caught_exception_types, **ignore)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m warning_list, debug(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    203\u001b[0m     simplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mOptimizationWarning)\n\u001b[1;32m--> 204\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# Resolve warnings and determine whether or not to retry\u001b[39;00m\n\u001b[0;32m    207\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\optim\\fit.py:164\u001b[0m, in \u001b[0;36mfit_gpytorch_mll_torch\u001b[1;34m(mll, parameters, bounds, closure, closure_kwargs, step_limit, stopping_criterion, optimizer, scheduler, callback, timeout_sec)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     closure \u001b[38;5;241m=\u001b[39m partial(closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclosure_kwargs)\n\u001b[1;32m--> 164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbounds_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\optim\\core.py:194\u001b[0m, in \u001b[0;36mtorch_minimize\u001b[1;34m(closure, parameters, bounds, callback, optimizer, scheduler, step_limit, timeout_sec, stopping_criterion)\u001b[0m\n\u001b[0;32m    188\u001b[0m _bounds \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    189\u001b[0m     {}\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m {name: limits \u001b[38;5;28;01mfor\u001b[39;00m name, limits \u001b[38;5;129;01min\u001b[39;00m bounds\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m parameters}\n\u001b[0;32m    192\u001b[0m )\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, step_limit \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 194\u001b[0m     fval, _ \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     runtime \u001b[38;5;241m=\u001b[39m monotonic() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m    196\u001b[0m     result \u001b[38;5;241m=\u001b[39m OptimizationResult(\n\u001b[0;32m    197\u001b[0m         step\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m    198\u001b[0m         fval\u001b[38;5;241m=\u001b[39mfval\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[0;32m    199\u001b[0m         status\u001b[38;5;241m=\u001b[39mOptimizationStatus\u001b[38;5;241m.\u001b[39mRUNNING,\n\u001b[0;32m    200\u001b[0m         runtime\u001b[38;5;241m=\u001b[39mruntime,\n\u001b[0;32m    201\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\optim\\closures\\core.py:64\u001b[0m, in \u001b[0;36mForwardBackwardClosure.__call__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tuple[Optional[Tensor], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_manager():\n\u001b[1;32m---> 64\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m         value \u001b[38;5;241m=\u001b[39m values \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreducer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreducer(values)\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward(value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\botorch\\optim\\closures\\model_closures.py:162\u001b[0m, in \u001b[0;36m_get_loss_closure_fallback_internal.<locals>.closure\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    161\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m mll\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39mmll\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_inputs)\n\u001b[1;32m--> 162\u001b[0m     log_likelihood \u001b[38;5;241m=\u001b[39m \u001b[43mmll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlog_likelihood\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\mlls\\variational_elbo.py:77\u001b[0m, in \u001b[0;36mVariationalELBO.forward\u001b[1;34m(self, variational_dist_f, target, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, variational_dist_f, target, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    Computes the Variational ELBO given :math:`q(\\mathbf f)` and :math:`\\mathbf y`.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    Calling this function will call the likelihood's :meth:`~gpytorch.likelihoods.Likelihood.expected_log_prob`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    :return: Variational ELBO. Output shape corresponds to batch shape of the model/input data.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariational_dist_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\mlls\\_approximate_mll.py:59\u001b[0m, in \u001b[0;36m_ApproximateMarginalLogLikelihood.forward\u001b[1;34m(self, approximate_dist_f, target, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m num_batch \u001b[38;5;241m=\u001b[39m approximate_dist_f\u001b[38;5;241m.\u001b[39mevent_shape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     58\u001b[0m log_likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_likelihood_term(approximate_dist_f, target, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mdiv(num_batch)\n\u001b[1;32m---> 59\u001b[0m kl_divergence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariational_strategy\u001b[49m\u001b[38;5;241m.\u001b[39mkl_divergence()\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_data \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Add any additional registered loss terms\u001b[39;00m\n\u001b[0;32m     62\u001b[0m added_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(log_likelihood)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SingleTaskGP' object has no attribute 'variational_strategy'"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "#mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Use an acquisition function (Expected Improvement in this case)\n",
    "acqf = ExpectedImprovement(model=model, best_f=train_y.max())\n",
    "\n",
    "# Find the next point to evaluate by maximizing the acquisition function\n",
    "bounds = torch.tensor([[0.], [1.]])  # Define bounds of the search space\n",
    "candidate, _ = optimize_acqf(acqf, bounds=bounds, q=1, num_restarts=5, raw_samples=20)\n",
    "\n",
    "# Evaluate the objective function at the new candidate point\n",
    "new_y = objective_function(candidate)\n",
    "\n",
    "# Update training data and repeat\n",
    "train_x = torch.cat([train_x, candidate])\n",
    "train_y = torch.cat([train_y, new_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "RtaG4f-tmqhA",
    "outputId": "3963dbc8-5b4b-457e-a631-270cbd3457d9"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 28538020624 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m output \u001b[38;5;241m=\u001b[39m model(train_x)\n\u001b[1;32m---> 19\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mmll\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\mlls\\variational_elbo.py:77\u001b[0m, in \u001b[0;36mVariationalELBO.forward\u001b[1;34m(self, variational_dist_f, target, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, variational_dist_f, target, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    Computes the Variational ELBO given :math:`q(\\mathbf f)` and :math:`\\mathbf y`.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    Calling this function will call the likelihood's :meth:`~gpytorch.likelihoods.Likelihood.expected_log_prob`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    :return: Variational ELBO. Output shape corresponds to batch shape of the model/input data.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariational_dist_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\mlls\\_approximate_mll.py:58\u001b[0m, in \u001b[0;36m_ApproximateMarginalLogLikelihood.forward\u001b[1;34m(self, approximate_dist_f, target, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Get likelihood term and KL term\u001b[39;00m\n\u001b[0;32m     57\u001b[0m num_batch \u001b[38;5;241m=\u001b[39m approximate_dist_f\u001b[38;5;241m.\u001b[39mevent_shape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 58\u001b[0m log_likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_likelihood_term\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapproximate_dist_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv(num_batch)\n\u001b[0;32m     59\u001b[0m kl_divergence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mvariational_strategy\u001b[38;5;241m.\u001b[39mkl_divergence()\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_data \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Add any additional registered loss terms\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\mlls\\variational_elbo.py:61\u001b[0m, in \u001b[0;36mVariationalELBO._log_likelihood_term\u001b[1;34m(self, variational_dist_f, target, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_log_likelihood_term\u001b[39m(\u001b[38;5;28mself\u001b[39m, variational_dist_f, target, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlikelihood\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariational_dist_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gpytorch\\likelihoods\\gaussian_likelihood.py:64\u001b[0m, in \u001b[0;36m_GaussianLikelihoodBase.expected_log_prob\u001b[1;34m(self, target, input, *params, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m     target \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mobservation_nan_policy\u001b[38;5;241m.\u001b[39m_fill_tensor(target)\n\u001b[0;32m     63\u001b[0m mean, variance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mvariance\n\u001b[1;32m---> 64\u001b[0m res \u001b[38;5;241m=\u001b[39m ((\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m)\u001b[38;5;241m.\u001b[39msquare() \u001b[38;5;241m+\u001b[39m variance) \u001b[38;5;241m/\u001b[39m noise \u001b[38;5;241m+\u001b[39m noise\u001b[38;5;241m.\u001b[39mlog() \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi)\n\u001b[0;32m     65\u001b[0m res \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mmul(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nan_policy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 28538020624 bytes."
     ]
    }
   ],
   "source": [
    "# Switch to training mode\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Define optimizer and loss (Variational ELBO)\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=0.01)\n",
    "\n",
    "# Variational ELBO objective\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "\n",
    "# Training loop\n",
    "num_iterations = 200\n",
    "for i in range(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 2 == 0:\n",
    "        print(f'Iter {i + 1}/{num_iterations} - Loss: {loss.item():.3f}')\n",
    "        plt.plot(i, loss.detach().numpy())\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Loss vs. Iteration\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p__Bx5xtkHOM"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_preds = likelihood(model(test_x))\n",
    "    mean = test_preds.mean\n",
    "    lower, upper = test_preds.confidence_region()\n",
    "\n",
    "# Print a few results\n",
    "print(f\"Predicted Mean: {mean[:10]}\")\n",
    "print(f\"Lower Bound: {lower[:10]}\")\n",
    "print(f\"Upper Bound: {upper[:10]}\")\n",
    "\n",
    "\n",
    "# Convert predictions and true values to NumPy for performance metrics\n",
    "mean_np = mean.numpy()\n",
    "test_y_np = test_y.numpy()\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(test_y_np, mean_np)\n",
    "mse = mean_squared_error(test_y_np, mean_np)\n",
    "r2 = r2_score(test_y_np, mean_np)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"R-squared (R²): {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PuzgJXiagwh6"
   },
   "outputs": [],
   "source": [
    "def vpbo_loop1(trials, split_num, liminit, fcores, afcores, refcores, data, test_data):\n",
    "    trialspltvar = trials #epochs actually\n",
    "    splitvar = split_num  #number of splits the data will be in. In our case, four splits\n",
    "\n",
    "    div = int(dim/splitvar)    #dim is total number of features\n",
    "    #sf = scaling_factor\n",
    "    x0 = np.random.uniform(splitvar, dim)\n",
    "\n",
    "    x = liminit*np.ones((splitvar, dim))\n",
    "    lwr = x.copy()\n",
    "    upr = x.copy()+1e-6\n",
    "    mll = {}\n",
    "    gp = {}\n",
    "    acq_fun = {}\n",
    "    bnds_var = {}\n",
    "# Simulate BO\n",
    "    for i in range(splitvar):\n",
    "        if fcores == 1:\n",
    "                Xbs[0] = x\n",
    "        else:\n",
    "                for i in range(fcores-1):\n",
    "                    Xbs[i] = x[i*splt:(i+1)*splt, :]\n",
    "                Xbs[-1] = x[(i+1)*splt:, :]\n",
    "\n",
    "        feature_cols=filtered_correlations(data, label_col[i+1]).index.intersection(input_variables)\n",
    "        # Initialize train/test data\n",
    "        test_data = test_data\n",
    "\n",
    "        #data = data.sample(frac=1.)\n",
    "\n",
    "        X = data[feature_cols].to_numpy()\n",
    "        y = data[label_col[i+1]].to_numpy()\n",
    "\n",
    "        X_train = torch.from_numpy(X[:-test_data])\n",
    "        y_train = torch.from_numpy(y[:-test_data])\n",
    "\n",
    "        X_test = torch.from_numpy(X[-test_data:])\n",
    "        y_test = torch.from_numpy(y[-test_data:])\n",
    "        # Add an extra dimension to Y_train and Y_test\n",
    "        y_train = y_train.unsqueeze(1)  # Shape: [13059, 1]\n",
    "        y_test = y_test.unsqueeze(1)    # Shape: [2000, 1]\n",
    "\n",
    "        print(f\"X-Train set: {X_train.shape}\")\n",
    "        print(f\"Y-Train set: {y_train.shape}\")\n",
    "        print(f\"X-Test set: {X_test.shape}\")\n",
    "        print(f\"Y-Test set: {y_test.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "        # 1. Create a new GP with the best setup\n",
    "        gp[str(i+1)], mll[str(i+1)] = get_gp(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            ConstantMean(),\n",
    "            ScaleKernel(RBFKernel()),\n",
    "            GaussianLikelihood()\n",
    "        )\n",
    "\n",
    "        mll[str(i+1)] = fit_gpytorch_mll(mll[str(i+1)])\n",
    "        bnds_var[str(i+1)] = Bounds(lwr[i], upr[i])\n",
    "        # 2. Define and optimize an acquisition function\n",
    "        acq_fun[str(i+1)] = ExpectedImprovement(model=gp[str(i+1)],\n",
    "                                                best_f=torch.min(y_train))\n",
    "\n",
    "        X_new, acqf_val  = Parallel(n_jobs = afcores)(delayed(optimize_acqf(\n",
    "                                                                    acq_fun[str(i+1)],\n",
    "                                                                    bounds=bounds,\n",
    "                                                                    q=1, num_restarts=5,raw_samples=20,\n",
    "                                                                    inequality_constraints=ineq_constraint\n",
    "                                                                    )\n",
    "                                                        )\n",
    "                                                    for x_0 in x0)\n",
    "\n",
    "        X_new = torch.round(X_new, decimals=1)\n",
    "\n",
    "          # 3.a (Optional) Find the closes test point\n",
    "        best_idx = -1\n",
    "        best_dist = np.inf\n",
    "        for idx, test_point in enumerate(X_test):\n",
    "            cur_dist = euclidean(X_new.squeeze(), test_point)\n",
    "            if cur_dist < best_dist:\n",
    "                best_dist = cur_dist\n",
    "                best_idx = idx\n",
    "\n",
    "        # 3.b Update the dataset by adding the new point\n",
    "        X_test_new = X_test[best_idx]\n",
    "        y_test_new = y_test[best_idx]\n",
    "\n",
    "        # Remove from test set\n",
    "        # Remove from test set\n",
    "        X_test = torch.cat((X_test[:best_idx], X_test[best_idx + 1:]))\n",
    "        y_test = torch.cat((y_test[:best_idx], y_test[best_idx + 1:]))\n",
    "\n",
    "        print(f\"Round: {i}\")\n",
    "        print(f\" - New experimental point: {X_new}\")\n",
    "        print(f\" - New acquisition value: {acqf_val}\")\n",
    "        print(f\" - Test point: {X_test_new}\")\n",
    "        print(f\" - Test evaluation: {y_test_new}\")\n",
    "        print(F\" - Dataset shape: {X_train.shape[0]}\")\n",
    "        print(\"\")\n",
    "\n",
    "        X_train = torch.vstack((X_train, X_test_new))\n",
    "        y_train = torch.vstack((y_train, y_test_new))\n",
    "\n",
    "        '''\n",
    "          X_test_new = np.array([res.x for res in opt], dtype = 'float')\n",
    "          acqf_val = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
    "          X_test_new[i] = X_test_new[np.argmin(acqf_val)]\n",
    "          X_test_new[-1, i*div:(i+1)*div] = X_test_new[np.argmin(acqf_val), i*div:(i+1)*div]\n",
    "\n",
    "          X_new_best = np.array(np.ones(fcores), dtype = tuple)\n",
    "'''\n",
    "\n",
    "        for j in range(splitvar):\n",
    "             if any(y_test_new[:,j] < min(y[:,j])):\n",
    "                lwr[j] = X_test_new[np.argmin(y_test_new[:, j])]\n",
    "                lwr[j, j*div:(j+1)*div] = bounds.lb[j]\n",
    "                upr[j] = X_test_new[np.argmin(y_test_new[:, j])]+1e-6\n",
    "                upr[j, j*div:(j+1)*div] = bounds.ub[j]\n",
    "\n",
    "        for j in range(splitvar):\n",
    "            mll[str(j+1)] = fit_gpytorch_mll(mll[str(j+1)])\n",
    "            bnds_var[str(j+1)] = Bounds(lwr[j], upr[j])\n",
    "            acq_fun[str(j+1)] = ExpectedImprovement(model=gp[str(j+1)],\n",
    "                                                best_f=torch.min(y_train))\n",
    "            [str(j+1)].fit(x, eps[:, j])\n",
    "            X_test_new, acqf_val = Parallel(n_jobs = af_cores)(delayed(optimize_acqf(\n",
    "                                                                    acq_fun[str(j+1)],\n",
    "                                                                    bounds=bounds,\n",
    "                                                                    q=1, num_restarts=5,raw_samples=20,\n",
    "                                                                    inequality_constraints=ineq_constraint\n",
    "                                                                    )\n",
    "                                                        )\n",
    "                                                    for start_point in x0)\n",
    "\n",
    "            '''X_test_new = np.array([res.x for res in opt], dtype = 'float')\n",
    "            acqf_val = np.array([np.atleast_1d(res.fun)[0] for res in opt])'''\n",
    "            X_test_new[j] = X_test_new[np.argmin(acqf_val)]\n",
    "            X_test_new[-1, j*div:(j+1)*div] = X_test_new[np.argmin(acqf_val), j*div:(j+1)*div]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GUoGiGdefkf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as pyp\n",
    "from scipy.optimize import minimize, Bounds, approx_fprime, NonlinearConstraint\n",
    "from joblib import Parallel, delayed\n",
    "import sklearn.gaussian_process as gpr\n",
    "from collections import OrderedDict\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7x0kyqXNeg79"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from scipy.optimize import minimize, Bounds\n",
    "\n",
    "class MyOptimizer:\n",
    "    def __init__(self, train_x, train_y, bounds, kernel, exp_w):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.bounds = bounds  # Bounds for input variables\n",
    "        self.kernel = kernel  # Kernel for GPR\n",
    "        self.exp_w = exp_w    # Weighting for exploration/exploitation in acquisition function\n",
    "        self.dim = train_x.shape[1]\n",
    "        self.args = []\n",
    "        self.ref_args = []\n",
    "        self.dist_ref = {}  # For reference models\n",
    "\n",
    "    def distmod(self, x, *args):\n",
    "        \"\"\"\n",
    "        This is a placeholder function for the GP model.\n",
    "        Replace this function with actual logic for your model, using self.train_x and self.train_y.\n",
    "        \"\"\"\n",
    "        # Example GP using train_x and train_y\n",
    "        model = GPR(kernel=self.kernel, alpha=1e-6, n_restarts_optimizer=10, normalize_y=True)\n",
    "        model.fit(self.train_x, self.train_y)\n",
    "        return model.predict(x)  # Predicting at new x\n",
    "\n",
    "    def descale(self, x):\n",
    "        m = (self.ub-self.lb)/(self.bounds.ub-self.bounds.lb)\n",
    "        b = self.ub-m*self.bounds.ub\n",
    "        return m*x+b\n",
    "\n",
    "    def scale(self, x, use_self = True, lb = None, ub = None):\n",
    "        if use_self:\n",
    "            m = (self.bounds.ub-self.bounds.lb)/(self.ub-self.lb)\n",
    "            b = self.bounds.ub-m*self.ub\n",
    "        else:\n",
    "            m = (self.bounds.ub-self.bounds.lb)/(ub-lb)\n",
    "            b = self.bounds.ub-m*ub\n",
    "        return m*x+b\n",
    "\n",
    "    def optimizer_vpbo(self, trials, split_num, lim_init,\n",
    "                         f_cores=1, af_cores=1, ref_cores=1, x_init=None):\n",
    "\n",
    "        print('Variable Partitioned BO run...')\n",
    "        start = time.time()\n",
    "        self.trials_vp = trials\n",
    "        splits = split_num\n",
    "        self.time_vp = np.zeros(self.trials_vp)\n",
    "        self.time_fvp = np.zeros(self.trials_vp)\n",
    "        div = int(self.dim / splits)\n",
    "        ref_mod = self.dist_ref.get('distrefmod', lambda x: 0)  # Use the reference model, or a default zero-return function\n",
    "\n",
    "        x = lim_init * np.ones((splits, self.dim))\n",
    "\n",
    "        lwr = x.copy()\n",
    "        upr = x.copy() + 1e-6\n",
    "        for i in range(splits):\n",
    "            if x_init is None:\n",
    "                x[i, i*div:(i+1)*div] = np.random.uniform(self.bounds['lb'],\n",
    "                                                          self.bounds['ub'],\n",
    "                                                          (1, div))\n",
    "            else:\n",
    "                x_init = x_init.reshape(1, self.dim)\n",
    "                x[i, i*div:(i+1)*div] = x_init[0, i*div:(i+1)*div]\n",
    "            lwr[i, i*div:(i+1)*div] = self.bounds['lb'][i]\n",
    "            upr[i, i*div:(i+1)*div] = self.bounds['ub'][i]\n",
    "        x = np.vstack([x, lim_init])\n",
    "\n",
    "        init_pts = int(len(x) / splits)\n",
    "        splt = int(x.shape[0] / f_cores)\n",
    "        x_bs = np.array(np.ones(f_cores), dtype=tuple)\n",
    "\n",
    "        if f_cores == 1:\n",
    "            x_bs[0] = x\n",
    "        else:\n",
    "            for i in range(f_cores - 1):\n",
    "                x_bs[i] = x[i * splt:(i + 1) * splt, :]\n",
    "            x_bs[-1] = x[(i + 1) * splt:, :]\n",
    "\n",
    "        # Run the distmod for function evaluation\n",
    "        start_f = time.time()\n",
    "        y = Parallel(n_jobs=f_cores)(delayed(self.distmod)(self.descale(x_s), *self.args)\n",
    "                                     for x_s in x_bs)\n",
    "\n",
    "        # Reference model evaluation\n",
    "        if callable(ref_mod):\n",
    "            y_ref = Parallel(n_jobs=ref_cores)(delayed(ref_mod)(self.descale(x_s), *self.ref_args)\n",
    "                                               for x_s in x_bs)\n",
    "            y_ref = np.vstack(y_ref[:])\n",
    "        else:\n",
    "            y_ref = np.zeros_like(y)\n",
    "\n",
    "        end_f = time.time()\n",
    "        self.time_fvp[0] = end_f - start_f\n",
    "\n",
    "        # Stack outputs\n",
    "        y = np.vstack(y[:])\n",
    "        eps = y - y_ref\n",
    "        y_bst = np.min(y, axis=0).reshape(-1, 1).T\n",
    "\n",
    "        # Gaussian Process Models for each partition\n",
    "        bnds_var = {}\n",
    "        model_vp = {}\n",
    "        LCB = {}\n",
    "\n",
    "        for i in range(splits):\n",
    "            model_vp[str(i + 1)] = GPR(self.kernel, alpha=1e-6, n_restarts_optimizer=10, normalize_y=True)\n",
    "            model_vp[str(i + 1)].fit(x, eps[:, i])\n",
    "            bnds_var[str(i + 1)] = Bounds(lwr[i], upr[i])\n",
    "            LCB[str(i + 1)] = self._build_lcb_function(model_vp[str(i + 1)], i + 1)\n",
    "\n",
    "        restarts = int(round(128 / (splits + 1), 0))\n",
    "        x_nxt = x.copy()\n",
    "\n",
    "        for i in range(self.trials_vp - init_pts):\n",
    "            x0 = np.random.uniform(self.bounds.lb, self.bounds.ub, (restarts, self.dim))\n",
    "\n",
    "            for j in range(splits):\n",
    "                opt = Parallel(n_jobs=af_cores)(delayed(minimize)(LCB[str(j + 1)],\n",
    "                                                                  x_0,\n",
    "                                                                  method='L-BFGS-B',\n",
    "                                                                  bounds=bnds_var[str(j + 1)])\n",
    "                                                for x_0 in x0)\n",
    "                x_nxt[j] = opt[np.argmin([res.fun for res in opt])].x\n",
    "\n",
    "            # Function evaluations at next points\n",
    "            y_nxt = Parallel(n_jobs=f_cores)(delayed(self.distmod)(self.descale(x_s), *self.args)\n",
    "                                             for x_s in x_nxt)\n",
    "            y_nxt = np.vstack(y_nxt[:])\n",
    "\n",
    "            # Update best and other values\n",
    "            y = np.vstack([y, y_nxt])\n",
    "            y_bst = np.vstack([y_bst, np.min(y_nxt, axis=0).reshape(-1, 1).T])\n",
    "\n",
    "        # Final output storage\n",
    "        self.x_vp = self.descale(x)\n",
    "        self.y_vp = y\n",
    "        self.y_vpbst = y_bst\n",
    "\n",
    "    def _build_lcb_function(self, model, partition_idx):\n",
    "        \"\"\"\n",
    "        Build the Lower Confidence Bound acquisition function.\n",
    "        \"\"\"\n",
    "        def lcb(x):\n",
    "            mean, std = model.predict(x, return_std=True)\n",
    "            return mean - self.exp_w * std\n",
    "        return lcb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXOLeq58iBmm"
   },
   "outputs": [],
   "source": [
    "# Assuming you have the following:\n",
    "bounds = {'lb': np.zeros((2,69)), 'ub': np.ones((2,69))}  # Example bounds\n",
    "kernel = None  # Replace with actual kernel for GPR\n",
    "exp_w = 0.1    # Exploration weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjeVjJQGiwwe",
    "outputId": "838fbd63-7156-4834-ae25-598b7cb625ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds['lb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "U_CB0JnKgX5p",
    "outputId": "8ca15dd0-3b9a-43b6-8855-6b7f7bfd3466"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MyOptimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2c3b392cf4db>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate and run optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlim_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m69\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Initial limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_vpbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlim_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlim_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MyOptimizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate and run optimization\n",
    "optimizer = MyOptimizer(train_x, train_y, bounds, kernel, exp_w)\n",
    "lim_init = np.ones((2,69)) # Initial limits\n",
    "optimizer.optimizer_vpbo(trials=10, split_num=2, lim_init=lim_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9inRrToEhIE"
   },
   "outputs": [],
   "source": [
    "def vpbo_final:\n",
    "  print('Variable Partitioned BO run...')\n",
    "  model_vp = {}\n",
    "  for i in range(splits):\n",
    "    model_vp[str(i+1)] = model(kernel,\n",
    "                             alpha=1e-6,\n",
    "                             n_restarts_optimizer=10,\n",
    "                             normalize_y=True)\n",
    "    model_vp[str(i+1)].fit(x, eps[:, i])\n",
    "    bnds_var[str(i+1)] = Bounds(lwr[i], upr[i])\n",
    "    LCB[str(i+1)] = build_lcb_function(model_vp[str(i+1)], i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "gCGXjAw0VezI",
    "outputId": "c0c71b44-1cb9-4f54-de5e-37123976b8e1"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-c314251a1101>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Use joblib to train models for each output variable in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m all_trained_models = Parallel(n_jobs=1)(\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_for_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_y_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_y1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-c314251a1101>\u001b[0m in \u001b[0;36mtrain_for_variable\u001b[0;34m(train_x, train_y_variable, batch_size)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# Train the model over batches for this particular output variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import gpytorch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming train_x is your input data and train_y is a list or tuple with 4 output variables\n",
    "# train_y = (train_y1, train_y2, train_y3, train_y4)\n",
    "# Each train_yi is a tensor corresponding to an output variable\n",
    "\n",
    "# Function to train the model for a specific output variable\n",
    "def train_model_for_output(train_x, train_y_output, inducing_points):\n",
    "    model = SparseGPModel(inducing_points)\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "    # Use the Adam optimizer\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.parameters()},\n",
    "        {'params': likelihood.parameters()},\n",
    "    ], lr=0.1)\n",
    "\n",
    "    # \"Loss\" for GPs - the variational ELBO\n",
    "    mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y_output.size(0))\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    training_iterations = 100\n",
    "    for i in range(training_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x)\n",
    "        loss = -mll(output, train_y_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 2 == 0:\n",
    "          print(f'Iter {i + 1}/{training_iterations} - Loss: {loss.item():.3f}')\n",
    "\n",
    "    return model, likelihood\n",
    "\n",
    "# Define function to parallelize over different output variables\n",
    "def train_for_variable(train_x, train_y_variable, batch_size=10000):\n",
    "    # Split the output data into batches\n",
    "    train_dataset = TensorDataset(train_x, train_y_variable)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Process each batch independently\n",
    "    def process_batch(batch):\n",
    "        batch_x, batch_y = batch\n",
    "        inducing_points = batch_x[::16]  # Select inducing points from the batch\n",
    "        model, likelihood = train_model_for_output(batch_x, batch_y, inducing_points)\n",
    "        return model, likelihood\n",
    "\n",
    "    # Train the model over batches for this particular output variable\n",
    "    models = Parallel(n_jobs=2)(delayed(process_batch)(batch) for batch in train_loader)\n",
    "    return models\n",
    "\n",
    "# Now use joblib to parallelize the training over the 4 different output variables\n",
    "train_y1, train_y2, train_y3 = train_y.T\n",
    "\n",
    "# Use joblib to train models for each output variable in parallel\n",
    "all_trained_models = Parallel(n_jobs=1)(\n",
    "    delayed(train_for_variable)(train_x, train_y_output)\n",
    "    for train_y_output in [train_y1, train_y2, train_y3]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (bio-ai-38)",
   "language": "python",
   "name": "bio-ai-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
